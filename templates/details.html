{% extends "base.html" %}
{% block content %}

<div class="container">

	<div class="blog-header">
		<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Dataset">
		<h1 style="padding-top: 50px; margin-top: -50px;" class="blog-title">The Dataset</h1>
		</a>
	</div>
<div class="row">
	<div class="col-sm-12 blog-main">
		<!-- The Data -->
		<div class="blog-post">
		<p>All analysis was done using Lending Club's publically available loan data, which can be downloaded <b><a href="https://www.lendingclub.com/info/download-data.action">here</a></b>. This dataset consists of 750k loans dating back to 2007, and at the time of this analysis going up to 09/30/15. Lending Club assigns each loan a grade based on their risk assessment, which they use to set the interest rate for the loan.</p>

		<p>For each loan, we're given about 50 different pieces of information about the loan and the borrower, along with information about the loan's payment history and current status. The older loans that have matured will either have a status of 'fully paid' or they will have been 'charged off' (i.e. they will have defaulted and the ouststanding principal will have been written off). Most of the loans were issued relatively recently, however, and are still ongoing. So, we don't know their 'final outcome', but we're give their current status as either 'current', meaning the borrower is up-to-date on their payments, or they can be at various stages of delinquency. As expected, loans with lower grades (i.e. F) are more likely to be in a delinquent status.</p>
		<div class="row">
		<div class="col-sm-6">
		<img src="/static/images/year_cond_dist.png" width="500" class="img-responsive center-block"></img>
		</div>
		<div class="col-sm-6">
		<img src="/static/images/grade_cond_dists.png" width="500" class="img-responsive center-block"></img>
		</div>
		</div>
		</div>

	<!-- Measuring performance -->
	<div class="blog-header">
		<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Calc Exp Returns">
		<h1 style="padding-top: 50px; margin-top: -50px;" class="blog-title">Measuring loan performance</h1>
		</a>
		<p class="lead blog-description">A key first step to developing predictive models of loan outcomes using the Lending Club data is to establish a consistent metric of loan performance that can be applied to both matured and outstanding loans. To do this, I used the net annualized returns for 'fully observed' loans, and calculated its expected value conditioned on the available data for 'partially observed loans,' as described below.</p>

	</div>

<div class="row">
	<div class="col-sm-12 blog-main">

		<!-- NAR-->
		<div class="blog-post">
			<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Annualized Returns">
			<h2 style="padding-top: 50px; margin-top: -50px;" class="blog-post-title"> Net Annualized Returns (NAR)</h2>
			</a>
			<p>Calculating returns on matured loans is relatively straightforward, at least with the 'net annualized returns' (NAR) formula used by Lending Club. This simply calculates the percentage return in each month (interest made, minus service fees and principal lost through charge-offs), and then computes an average monthly return, weighted by the outstanding principal in each month. This in then converted into an annualized return by compounding monthly. </p>
			<img src="/static/images/LC_NAR_formula.png" width="700" class="img-responsive center-block"></img>
			<p>(Taken from the Lending Club <a href="https://www.lendingclub.com/public/lendersPerformanceHelpPop.action">website</a>)</p>
		</div>
		
		<!-- Hazard functions -->
		<div class="blog-post">
			<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Hazard Functions">
			<h2 style="padding-top: 50px; margin-top: -50px;" class="blog-post-title">Hazard Functions</h2>
			</a>
			<p>For outstanding loans it's more difficult because we don't know what the full payment outcome will be, so we can't directly calculate the NAR. The approach I took is to use the current status and payment history of each loan to estimate an 'expected' rate of return. To do this I first needed to compute the probabiliy that a given loan will go into default at each payment period. These probabilities are described by a 'hazard function', which I estimate for each loan grade, and for each loan term (36 month and 60 month loans).</p>

			<p>I used the <a href="https://en.wikipedia.org/wiki/Nelson%E2%80%93Aalen_estimator">Nelson-Aalen estimator</a>, implemented in the Python module <a href="http://lifelines.readthedocs.org/en/latest/">lifelines</a> to estimate the hazard functions. This analysis shows that riskier loans (lower letter grades) are both more likely to default overall, and are more likely to default earlier in the loan term (the hazard functions are shifted leftwards).</p>
			<img src="/static/images/hazard_funs.png" width="900" class="center-block"></img>
		</div>


		<!-- EXPECTED RETURNS-->
		<div class="blog-post">
			<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Expected Returns">
			<h2 style="padding-top: 50px; margin-top: -50px;"  class="blog-post-title">Expected Returns</h2>
			</a>
			<p>Given the hazard function for each loan type, estimating the expected return for a given loan is relatively straightforward. We first calculate the average monthly return (<i>MR</i>) that we would recieve if the loan defaulted at each possible payment period <i>MR</i>(<i>default</i><sub><i>i</i></sub>). We can then calculate the weighted average of <i>MR</i>, using the estimated default probabilities at each time point, converting it into an annualized return as follows:
			<center><img src="static/images/expected_returns.png?{{rnum}}" width="500"></img></center>
			For an outstanding loan, we set the default probabilities to zero for all payments that have already been received. We also use a heuristic strategy to incorporate the reported loan status. Specifically, I use the data Lending Club provides <a href="https://www.lendingclub.com/info/demand-and-credit-profile.action">here</a> (bottom of page) on the average fraction of principal recovered for loans in varying stages of delinquency. I also make the (admittedly questionable) assumption that if payment is resumed, the loan returns to having its original set of default probabilities for the remainder of its term.</p>
			<p>The figures below show how these expected return values depend on a loan's current status, grade and interest rate.</p>
			
		<div class="row">
<!-- 			<div class="col-sm-6">
				<img src="/static/images/ROI_def_prob.png?{{rnum}}" width="450" class="center-block"></img>
			</div>
 -->		<div class="col-sm-6">
			<img src="/static/images/int_ROI_joints.png?{{rnum}}" width="450" class="center-block"></img>
			</div>
		<!-- </div> -->
			<div class="col-sm-6">
			<img src="/static/images/returns_box.png?{{rnum}}" width="500" class="center-block"></img>
			</div>
		</div>
	</div>


	<!--<div class="blog-header">
	</div> -->
	</div>
	<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Modeling Details">
		<h1 style="padding-top: 50px; margin-top: -50px;"  class="blog-title">Modeling Details</h1>
		</a>
		<p class="lead blog-description">I treat predicting loan returns as a regression problem, with the target variable being the annualized ROI of each loan. This gives a more fine-grained analysis than simply predicting whether or not a loan will default.</p>

	<div class="row">
		<div class="col-sm-12 blog-main">

		<!-- FEATURE SELECTION-->
		<div class="blog-post">
			<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Cross validation">
			<h2 style="padding-top: 50px; margin-top: -50px;"  class="blog-post-title">Feature selection</h2>
			</a>
			<p>Lending Club provides a set of ~50 features specifying the initial state of each loan. Some of these features are not useful for predicting loan outcomes (i.e. a loan's unique ID number), others are redundant, and most of them need some sort of massaging to get them into a format that we can plug into the models. For full details on these feature transformations see the <a href="https://github.com/jmmcfarl/loan-picker">source code</a>.	I'm currently using 30 different features for each loan. Here are a few of the non-trivial 'feature engineering' steps I found useful:
			<ul>
  				<li>Transforming 3-digit borrower zip codes into latitude and longitude coordinates. One can also treat zip-code as a categorical variable but that leads to significant overfitting problems (and takes lots of memory with a one-hot encoding).</li>
  				<li>The text descriptions provided with each loan can be empty, or can have additional entries added at later dates. I separated this out into two features: total length of text, and number of separate descriptions added.</li>
  				<li>I used a one-hot encoding for all categorical variables (ideally one could use categorical variables directly, at least with the decision-trees, but apparently not using scikit-learn at this point.</li>
  				<li>While decision tree models are insensitive to the scale of the features, feature scale does matter for other models (e.g. linear regression). Thus, I used different affine transformations (scikit-learn's minMaxScaler, maxAbsScaler, standardScaler, and robustScaler transformations) for each ordinal feature (plus log-scaling in some cases).</li>
  			</ul>
		</p>
		</div>

		<div class="blog-post">
			<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Cross validation">
			<h2 style="padding-top: 50px; margin-top: -50px;"  class="blog-post-title">Model training and validation</h2>
			</a>
			<p>So far I've tried several different models, including linear regression, a linear support vector machine (SVM), gradient tree boosting, and random forests, but I'm looking to test other models (e.g. artificial neural network approaches) as well. For each model I select key parameters using a cross-validated grid-search. Final performance of each model is evaluated using 10-fold cross-validation.</p>
		</div>

		<div class="blog-post">
			<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Portfolio returns">
			<h2 style="padding-top: 50px; margin-top: -50px;"  class="blog-post-title">Estimating returns on loan portfolios</h2>
			</a>
			<p>Rather than measuring the ability of the models to predict the returns of individual loans (such as with an R2 value), a more useful/intuitive approach is to quantify the returns on a portfolio of loans selected using a particular model-based strategy. To do this, I estimate the returns on investment portfolios with <i>K</i> loans, where we select the <i>K</i> loans with the highest model-predicted returns. I then calculate the returns on these portfolios using the same 'NAR' formula above. This simply requres keeping track of the (expected) net gains recieved from each loan, as well as the (expected) cumulative sum of outstanding principal over the entire term (i.e., the denominator in the NAR equation). I could also of course weight different loans by their principal to get a more accurate reflection of their contribution to the portfolio, but I opted not to do that in order to avoid having the results be dominated by larger loans.</p>
				<img class="img-responsive center-block" src="/static/images/loan_pred_examp.png?{{rnum}}" width="500"></img>
		</div>

		<div class="blog-post">
			<br>
			<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Fitting classifiers">
			<h2 style="padding-top: 50px; margin-top: -50px;"  class="blog-post-title">Fitting classifiers</h2>
			</a>
			<p>In addition to building regression models, I also trained classifiers to predict each loan's default probability. This basically just involves taking the same set of features, plugging them into scikit-learn's classifier estimators (rather than regressors), and using the calculated default probabilities rather than the ROI as the target variable. For loans where we have observed the final outcome the default probability is either a one or zero, and we can treat this as a class label, however for unobserved loans it represents a class probability. Since scikit-learn's classifier fit functions don't accept class probabilities natively, we need to do a little massaging. To get around this, I used the 'sample_weights' optional input, and fed in each unobserved data point twice, once with each class label, using the estimated class probabilities as the sample weights. Since the probability predictions of random forest classifiers can tend to be biased, I also checked the reliability of the model's probability estimates. As seen in the figure below, the probability estimates were pretty well calibrated, and I didn't see any improvement when adding an additional calibration stage with isotonic regression.</p>
			<img class="img-responsive center-block" src="/static/images/class_calib.png?{{rnum}}" width="500"></img>

		</div>

		<!-- Post abut visualizing Random Forest regression -->
		<div class="blog-post">
			<br>
			<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Decision tree">
			<h2 style="padding-top: 50px; margin-top: -50px;"  class="blog-post-title">Visualizing decision tree regression</h2>
			</a>
			<p>As a fun aside, I made an animation illustrating how a decision tree regressor 'partitions' a 2d feature space (in this case, the geographic location of the borrower). Each frame of the animation shows the predicted loan returns for each location, using a decision tree with increasing 'tree depth'. As the decision tree depth increases, the number of 'partitions' of the input space, within which the model can estimate separate average returns, increases exponentially. For a random forest, we're basically estimating many such decision trees in parallel (using random samples of the datapoints and features), and then taking the average output over trees as our prediction.</p>
			<video class="img-responsive center-block" width="600" controls>
 			 <source src="/static/movies/tree_movie.mp4?{{rnum}}" type="video/mp4">
			Your browser does not support the video tag.
			</video>
			<img class="img-responsive center-block" src="/static/movies/tree_cbar.png?{{rnum}}" width="600"></img>
		</div>


<!-- 		<div class="blog-post">
			<a style="pointer-events: none; cursor: default; text-decoration: none;" name="Cross validation">
			<h2 style="padding-top: 50px; margin-top: -50px;"  class="blog-post-title">Controlling for overfitting</h2>
			</a>
			<p>As the tree depth increases, the model becomes more complex, allowing it to become 'overfit' to the training data. We can see this by comparing the prediction accuracy (R2) on both the training set (in-sample accuracy) and the test set (out-of-sample accuracy) for trees of different depths (again simply using only borrower location as a predictor). Random forests, which take the average prediction of an ensemble of decision trees, provide a means of reducing overfitting while maintaining the flexibility of more complicated models.</p>
			<img class="img-responsive center-block" src="/static/images/R2_vs_treedepth.png?{{rnum}}" width="900"></img>
		</div>
 -->


	</div>
</div>

{% endblock %}