{% extends "base.html" %}
{% block content %}

<div class="container">

	<div class="blog-header">
		<h1 class="blog-title">Predicting loan outcomes</h1>
<!-- 		<p class="lead blog-description">Blah blah.</p>
-->	
</div>

<div class="row">
	<div class="col-sm-12 blog-main">

		<!-- POST ABOUT DIFFERENT LOAN STATUSES-->
		<div class="blog-post">
			<div>
			<a style="pointer-events: none; cursor: default;" name="Feature Selection">
			<h2 style="padding-top: 50px; margin-top: -50px;" class="blog-post-title">Feature Selection</h2>
			</a>
			<p>There are many other loan features, in addition to borrower location, that we can add to our random forest model. To determine the relative importance of each loan feature we can measure how much the prediction accuracy decreases if we randomly shuffle the values of that loan feature in the test set. This analysis shows that borrower location has relatively low importance compared with some of the loan features more directly associated with a borrower's credit history</p>
				<img class="img-responsive center-block" src="/static/images/fullRF_feature_imp.png?{{rnum}}" width="600"></img>
			</div>

			<div>
			<a style="pointer-events: none; cursor: default;" name="Comparing Models">
			<h2 style="padding-top: 50px; margin-top: -50px;" class="blog-post-title">Comparing Models</h2>
			</a>
			<p>Comparing returns on portfolios of varying sizes, selected using different models, we see that even a model based only on the borrower's location can provide significantly better returns compared to chance. The full random forest model, using all loan features, can provide increases in returns of up to 10%. This analysis also shows that the number of loans in the portfolio also serves to control the bias/variance tradeoff, with larger portfolios having decreased variance (and hence lower risk), but higher bias (worse average performance).</p>
				<img class="img-responsive center-block" src="/static/images/full_mod_compare.png?{{rnum}}" width="700"></img>
			</div>

			<div>
			<a style="pointer-events: none; cursor: default;" name="Grade Returns">
			<h2 style="padding-top: 50px; margin-top: -50px;" class="blog-post-title">Returns by risk level</h2>
			</a>
			<p>Another important questions is the extent to which these models are improving the returns for loans across all risk levels (i.e. loan grades), or whether they are simply telling us to select from the riskier loans which have better average returns. To look at this, we can compare the portfolio returns for different models at each loan grade. Riskier loans (higher grades) do tend to provide better returns overall, but the models substantially improve returns even for loans of a given grade.</p>
			<div class="row">
				<div class="col-sm-6">
			<img class="img-responsive center-block" src="/static/images/grade_returns.png?{{rnum}}" width="500"></img>
				</div>
				<div class="col-sm-6">
			<img class="img-responsive center-block" src="/static/images/picked_grades_props.png?{{rnum}}" width="500"></img>
				</div>
			</div>
			</div>
		
			<div>
			<a style="pointer-events: none; cursor: default;" name="Time Validation">
			<h2 style="padding-top: 50px; margin-top: -50px;" class="blog-post-title">Generalizing predictions over time</h2>
			</a>
			<p>Traditional K-fold cross-validation, as used above, does not tell us how well our model predictions will generalize to future loans, where the relationship between loan features and outcomes may change. One way to estimate the future performance of the model is to train it on loans issued up to a certain date, and then test its performance on predicting 'future' loan outcomes. Since the marority of loans in the LC data set were recently issued, I chose a slightly different approach, where I trained the model on ~200k loans issued in 2015 (green region below), and then tested the ability of the model to predict loans issued at varying times in the past. This ensured that there was a sufficient number of loans in the training set, while allowing for validation on test sets that were well separated in time from the training set. Somewhat surprisingly, the improved returns provided by selecting loans based on the model predictions were well-preserved when testing on loans as far back as 2010.</p>
			<img class="img-responsive center-block" src="/static/images/time_validation.png?{{rnum}}" width="800"></img>
			</div>

			<div>
			<a style="pointer-events: none; cursor: default;" name="Available loans">
			<h2 style="padding-top: 50px; margin-top: -50px;" class="blog-post-title">Towards automated investing</h2>
			</a>
			<p>One of my next steps is to link into the Lending Club API, and show you which loans you should invest in, and what the projected returns are on portfolios of different sizes. For example, here I trained the models on all data up to the latest month, and then estimated the expected returns on loan portfolios of different sizes. Since we can't simply take the model-predicted returns at face value, I estimated the distributions of returns using a bootstrap resampling procedure. Specifically, I randomly assembled loan portfolios where the model-predicted returns were matched to those in the current data. I then used the calculated returns on these resampled portfolios to estimate a distribution of likely returns.</p>
			<img class="img-responsive center-block" src="/static/images/newloan_predict.png?{{rnum}}" width="600"></img>
			</div>

		</div>

	</div>
</div>

{% endblock %}